'use client'

import { useState, useRef, useEffect } from 'react'
import { Mic, MicOff, Upload, Play, Pause, Download, Share2, Sparkles, Headphones, Clock } from 'lucide-react'
import { cn } from '@/lib/utils'

interface Recording {
  id: string
  blob?: Blob
  audioUrl?: string
  duration: number
  timestamp: Date
}

interface Message {
  id: string
  role: 'user' | 'assistant'
  content: string
  audioUrl?: string
  timestamp: Date
}

interface Step {
  id: number
  title: string
  status: 'pending' | 'recording' | 'completed'
  prompt: string
}

export default function Home() {
  const [isRecording, setIsRecording] = useState(false)
  const [recordingTime, setRecordingTime] = useState(0)
  const [recordings, setRecordings] = useState<Recording[]>([])
  const [messages, setMessages] = useState<Message[]>([])
  const [currentStep, setCurrentStep] = useState(0)
  const [isProcessing, setIsProcessing] = useState(false)
  const [isUploading, setIsUploading] = useState(false)
  const [podcastUrl, setPodcastUrl] = useState<string | null>(null)
  const [podcastScript, setPodcastScript] = useState<string | null>(null)

  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const audioChunksRef = useRef<Blob[]>([])
  const recordingIntervalRef = useRef<NodeJS.Timeout | null>(null)
  const fileInputRef = useRef<HTMLInputElement>(null)
  const audioStreamRef = useRef<MediaStream | null>(null)
  const [isAiThinking, setIsAiThinking] = useState(false)

  const getStepStatus = (stepId: number): 'pending' | 'recording' | 'completed' => {
    if (stepId < currentStep) return 'completed'
    if (stepId === currentStep) return 'recording'
    return 'pending'
  }

  const steps: Step[] = [
    {
      id: 1,
      title: "å›å¿†ç¬é—´",
      status: getStepStatus(1),
      prompt: "æˆ‘ä»¬ä¸éœ€è¦ä¸€ä¸ªå®Œæ•´æ•…äº‹ã€‚å°±è¯´æœ€è¿‘ä¸€æ¬¡ï¼Œä½ çªç„¶è§‰å¾—'æœ‰ç‚¹ä¸å¯¹åŠ²'çš„æ—¶å€™ã€‚ä½ æƒ³åˆ°çš„ç¬¬ä¸€ä¸ªç”»é¢æ˜¯ä»€ä¹ˆï¼Ÿ"
    },
    {
      id: 2,
      title: "é‡å»ºç°åœº",
      status: getStepStatus(2),
      prompt: "ä½ èƒ½å¸¦æˆ‘å›åˆ°é‚£ä¸ªç¬é—´å—ï¼Ÿå½“æ—¶å…·ä½“å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ"
    },
    {
      id: 3,
      title: "è‡ªæˆ‘è®¤çŸ¥",
      status: getStepStatus(3),
      prompt: "å¦‚æœç°åœ¨å›å¤´çœ‹é‚£ä¸€åˆ»ï¼Œä½ ä¼šæ€ä¹ˆå½¢å®¹å½“æ—¶çš„è‡ªå·±ï¼Ÿ"
    }
  ]

  useEffect(() => {
    // åˆå§‹åŒ–æ¬¢è¿æ¶ˆæ¯
    setMessages([{
      id: '1',
      role: 'assistant',
      content: 'ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„AIè¯­éŸ³æ’­å®¢ç¼–å¯¼ã€‚æˆ‘ä»¬å°†é€šè¿‡3æ®µå¯¹è¯ï¼ŒæŠŠä½ çš„æ•…äº‹å˜æˆä¸€æœŸç²¾å½©çš„æ’­å®¢ã€‚',
      timestamp: new Date()
    }, {
      id: '2',
      role: 'assistant',
      content: steps[0].prompt,
      timestamp: new Date()
    }])

    // é¢„å…ˆè¯·æ±‚éº¦å…‹é£æƒé™å¹¶åˆå§‹åŒ–éŸ³é¢‘æµ
    initAudioStream()
  }, [])

  // åˆå§‹åŒ–éŸ³é¢‘æµ
  const initAudioStream = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100
        }
      })
      audioStreamRef.current = stream

      // é¢„å…ˆåˆ›å»ºMediaRecorderä½†ä¸å¼€å§‹å½•åˆ¶
      const options = { mimeType: 'audio/webm;codecs=opus' }
      const mediaRecorder = new MediaRecorder(stream, options)
      mediaRecorderRef.current = mediaRecorder

      console.log('éº¦å…‹é£æƒé™å·²è·å–ï¼Œå‡†å¤‡å°±ç»ª')
    } catch (err) {
      console.error('åˆå§‹åŒ–éŸ³é¢‘æµå¤±è´¥:', err)
    }
  }

  // å‘é€éŸ³é¢‘æµåˆ°åç«¯
  const sendAudioToBackend = async (audioChunk: Blob) => {
    try {
      // å°† Blob è½¬æ¢ä¸º ArrayBuffer
      const arrayBuffer = await audioChunk.arrayBuffer()

      // å‘é€åˆ°åç«¯ï¼ˆå³ä½¿åç«¯ä¸å­˜åœ¨ï¼‰
      fetch('/api/audio-stream', {
        method: 'POST',
        headers: {
          'Content-Type': 'audio/webm',
        },
        body: arrayBuffer,
      }).catch(err => {
        // å³ä½¿åç«¯ä¸å­˜åœ¨ä¹Ÿä¸æŠ¥é”™ï¼Œé™é»˜å¤„ç†
        console.log('éŸ³é¢‘æµå‘é€åˆ°åç«¯ï¼ˆåç«¯å¯ä»¥ä¸å­˜åœ¨ï¼‰')
      })
    } catch (error) {
      console.log('éŸ³é¢‘æµå¤„ç†:', error)
    }
  }

  // æ’­æ”¾AIå›å¤çš„æç¤ºéŸ³
  const playAiResponseSound = () => {
    try {
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
      const oscillator = audioContext.createOscillator()
      const gainNode = audioContext.createGain()

      oscillator.connect(gainNode)
      gainNode.connect(audioContext.destination)

      // è®¾ç½®æŸ”å’Œçš„å›å¤æç¤ºéŸ³
      oscillator.type = 'sine'
      oscillator.frequency.setValueAtTime(783.99, audioContext.currentTime) // G5
      oscillator.frequency.exponentialRampToValueAtTime(1046.50, audioContext.currentTime + 0.1) // C6

      gainNode.gain.setValueAtTime(0, audioContext.currentTime)
      gainNode.gain.linearRampToValueAtTime(0.1, audioContext.currentTime + 0.02)
      gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.2)

      oscillator.start(audioContext.currentTime)
      oscillator.stop(audioContext.currentTime + 0.2)
    } catch (err) {
      console.error('æ’­æ”¾æç¤ºéŸ³å¤±è´¥:', err)
    }
  }

  const startRecording = async () => {
    if (!mediaRecorderRef.current) {
      console.error('MediaRecorder æœªåˆå§‹åŒ–')
      alert('å½•éŸ³åŠŸèƒ½åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨åå†è¯•')
      return
    }

    try {
      audioChunksRef.current = []

      // ç«‹å³æ˜¾ç¤ºå½•éŸ³ä¸­æ¶ˆæ¯
      const recordingMessage: Message = {
        id: Date.now().toString(),
        role: 'assistant',
        content: 'ğŸ™ï¸ æ·±å‘¼å¸...æ…¢æ…¢è¯´ï¼Œæˆ‘åœ¨å¬',
        timestamp: new Date()
      }
      setMessages(prev => [...prev, recordingMessage])

      // è®¾ç½®æ•°æ®å¤„ç†å›è°ƒ
      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data)
          console.log('å½•éŸ³æ•°æ®:', event.data.size, 'bytes')

          // å‘é€éŸ³é¢‘æ•°æ®åˆ°åç«¯
          sendAudioToBackend(event.data)
        }
      }

      // è®¾ç½®å½•éŸ³ç»“æŸå›è°ƒ
      mediaRecorderRef.current.onstop = () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' })
        const audioUrl = URL.createObjectURL(audioBlob)
        console.log('å½•éŸ³å®Œæˆï¼ŒéŸ³é¢‘å¤§å°:', audioBlob.size, 'bytes')

        // ç§»é™¤"æ­£åœ¨å½•éŸ³"çš„æ¶ˆæ¯
        setMessages(prev => prev.filter(msg => msg.id !== recordingMessage.id))

        const newRecording: Recording = {
          id: Date.now().toString(),
          blob: audioBlob,
          audioUrl,
          duration: recordingTime,
          timestamp: new Date()
        }

        setRecordings(prev => [...prev, newRecording])

        // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        const userMessage: Message = {
          id: Date.now().toString(),
          role: 'user',
          content: `å½•éŸ³å®Œæˆ (${formatTime(recordingTime)})`,
          audioUrl,
          timestamp: new Date()
        }
        setMessages(prev => [...prev, userMessage])

        // æ¨¡æ‹Ÿè½¬å½•
        setTimeout(() => {
          const transcripts = [
            "é‚£å¤©æ™šä¸Šæˆ‘ç«™åœ¨å…¬å¸æ¥¼ä¸‹ï¼Œä¸€ç›´æ²¡è¿›å»ã€‚",
            "åœ¨è¡—å¯¹é¢ï¼Œé›¨ä¸‹å¾—æŒºå¤§çš„ï¼Œæˆ‘èº²åœ¨å±‹æªä¸‹é¢ã€‚",
            "å°±æ˜¯ä¸€ä¸ªç»ˆäºåœä¸‹æ¥çš„äººå§ã€‚"
          ]
          const transcript = transcripts[currentStep] || "..."

          // æ›´æ–°ç”¨æˆ·æ¶ˆæ¯çš„è½¬å½•æ–‡æœ¬
          setMessages(prev => prev.map(msg =>
            msg.id === userMessage.id ? { ...msg, content: transcript } : msg
          ))

          // è®¾ç½®AIæ€è€ƒçŠ¶æ€
          setIsAiThinking(true)

          // å»¶è¿Ÿæ˜¾ç¤ºAIå›å¤ï¼Œåˆ›é€ æœŸå¾…æ„Ÿ
          setTimeout(() => {
            setIsAiThinking(false)

            // å‡†å¤‡AIå“åº”
            if (currentStep < 2) {
              const aiMessage: Message = {
                id: (Date.now() + 1).toString(),
                role: 'assistant',
                content: steps[currentStep + 1].prompt,
                timestamp: new Date()
              }
              setMessages(prev => [...prev, aiMessage])
              setCurrentStep(prev => prev + 1)

              // æ’­æ”¾AIå›å¤çš„æç¤ºéŸ³
              playAiResponseSound()
            } else {
              // å®Œæˆä¸‰æ­¥ï¼Œç”Ÿæˆæ’­å®¢
              generatePodcast()
            }
          }, 2000)
        }, 1000)
      }

      // å¼€å§‹å½•éŸ³
      mediaRecorderRef.current.start(100)
      setIsRecording(true)
      console.log('å¼€å§‹å½•éŸ³...')

      // å¼€å§‹è®¡æ—¶
      recordingIntervalRef.current = setInterval(() => {
        setRecordingTime(prev => prev + 1)
      }, 1000)

      // æ’­æ”¾æ¸©æš–çš„æç¤ºéŸ³
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
      const oscillator = audioContext.createOscillator()
      const gainNode = audioContext.createGain()
      const filter = audioContext.createBiquadFilter()

      oscillator.connect(filter)
      filter.connect(gainNode)
      gainNode.connect(audioContext.destination)

      // è®¾ç½®æ¸©æš–çš„éŸ³è‰²
      oscillator.type = 'sine'
      oscillator.frequency.setValueAtTime(523.25, audioContext.currentTime) // C5
      oscillator.frequency.exponentialRampToValueAtTime(659.25, audioContext.currentTime + 0.1) // E5

      filter.type = 'lowpass'
      filter.frequency.value = 2000

      gainNode.gain.setValueAtTime(0, audioContext.currentTime)
      gainNode.gain.linearRampToValueAtTime(0.15, audioContext.currentTime + 0.05)
      gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.3)

      oscillator.start(audioContext.currentTime)
      oscillator.stop(audioContext.currentTime + 0.3)

    } catch (err) {
      console.error('å¯åŠ¨å½•éŸ³å¤±è´¥:', err)
      alert('å½•éŸ³å¯åŠ¨å¤±è´¥ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•')
    }
  }

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop()
      setIsRecording(false)
      setRecordingTime(0)

      if (recordingIntervalRef.current) {
        clearInterval(recordingIntervalRef.current)
      }
    }
  }

  const handleFileUpload = (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0]
    if (file && file.type.startsWith('audio/')) {
      setIsUploading(true)
      const audioUrl = URL.createObjectURL(file)

      const newRecording: Recording = {
        id: Date.now().toString(),
        audioUrl,
        duration: 0, // å®é™…åº”ç”¨ä¸­åº”è¯¥è§£æéŸ³é¢‘æ–‡ä»¶è·å–æ—¶é•¿
        timestamp: new Date()
      }

      setRecordings(prev => [...prev, newRecording])

      const userMessage: Message = {
        id: Date.now().toString(),
        role: 'user',
        content: `ä¸Šä¼ äº†éŸ³é¢‘æ–‡ä»¶: ${file.name}`,
        audioUrl,
        timestamp: new Date()
      }
      setMessages(prev => [...prev, userMessage])

      setIsUploading(false)

      // è®¾ç½®AIæ€è€ƒçŠ¶æ€
      setIsAiThinking(true)

      // ä¸Šä¼ åçš„AIå“åº”
      setTimeout(() => {
        setIsAiThinking(false)

        if (currentStep < 2) {
          const aiMessage: Message = {
            id: (Date.now() + 1).toString(),
            role: 'assistant',
            content: steps[currentStep + 1].prompt,
            timestamp: new Date()
          }
          setMessages(prev => [...prev, aiMessage])
          setCurrentStep(prev => prev + 1)
          playAiResponseSound()
        } else {
          generatePodcast()
        }
      }, 2000)
    }
  }

  const generatePodcast = async () => {
    setIsProcessing(true)

    // æ˜¾ç¤ºå¤„ç†ä¸­æ¶ˆæ¯
    const processingMessage: Message = {
      id: Date.now().toString(),
      role: 'assistant',
      content: 'æ­£åœ¨ä¸ºä½ ç”Ÿæˆæ’­å®¢ï¼Œè¿™éœ€è¦å‡ ç§’é’Ÿ...',
      timestamp: new Date()
    }
    setMessages(prev => [...prev, processingMessage])

    // æ¨¡æ‹Ÿæ’­å®¢ç”Ÿæˆ
    setTimeout(() => {
      const script = `ã€æ—ç™½ã€‘
æ¯ä¸ªäººéƒ½æœ‰ä¸€ä¸ªä¸å¾—ä¸é¢å¯¹è‡ªå·±çš„æ—¶åˆ»ã€‚

ã€ç”¨æˆ·åŸå£°ã€‘
"é‚£å¤©æ™šä¸Šæˆ‘ç«™åœ¨å…¬å¸æ¥¼ä¸‹ï¼Œä¸€ç›´æ²¡è¿›å»ã€‚"

ã€æ—ç™½ã€‘
æœ‰æ—¶å€™ï¼Œåœä¸‹æ¥ä¸æ˜¯æ”¾å¼ƒï¼Œè€Œæ˜¯ä¸ºäº†æ›´å¥½åœ°è®¤è¯†è‡ªå·±ã€‚

ã€ç”¨æˆ·åŸå£°ã€‘
"å°±æ˜¯ä¸€ä¸ªç»ˆäºåœä¸‹æ¥çš„äººå§ã€‚"

ã€æ—ç™½ã€‘
è¿™å°±æ˜¯ä»Šå¤©çš„æ•…äº‹ï¼Œä¸€ä¸ªå…³äºåœä¸‹çš„æ•…äº‹ã€‚`

      setPodcastScript(script)
      setPodcastUrl('https://www.soundhelix.com/examples/mp3/SoundHelix-Song-1.mp3')
      setIsProcessing(false)

      // æ›´æ–°å¤„ç†ä¸­æ¶ˆæ¯ä¸ºå®Œæˆæ¶ˆæ¯
      setMessages(prev => prev.map(msg =>
        msg.id === processingMessage.id ? {
          ...msg,
          content: 'ğŸ‰ ä½ çš„æ’­å®¢å·²ç»å‡†å¤‡å¥½äº†ï¼ç‚¹å‡»ä¸‹æ–¹æ’­æ”¾æŒ‰é’®å¬å¬æ•ˆæœã€‚'
        } : msg
      ))
    }, 3000)
  }

  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60)
    const secs = seconds % 60
    return `${mins}:${secs.toString().padStart(2, '0')}`
  }

  return (
    <>
      <style jsx>{`
        @keyframes heartbeat {
          0% {
            transform: scale(1);
            opacity: 0.8;
          }
          20% {
            transform: scale(1.05);
            opacity: 0.4;
          }
          40% {
            transform: scale(1.1);
            opacity: 0.2;
          }
          60% {
            transform: scale(1.15);
            opacity: 0.1;
          }
          80% {
            transform: scale(1.2);
            opacity: 0.05;
          }
          100% {
            transform: scale(1.5);
            opacity: 0;
          }
        }

        @keyframes pulse-ring {
          0% {
            transform: scale(0.95);
            opacity: 1;
          }
          40% {
            transform: scale(1.3);
            opacity: 0.5;
          }
          100% {
            transform: scale(1.6);
            opacity: 0;
          }
        }

        .heartbeat-animation {
          animation: heartbeat 2s ease-in-out infinite;
        }

        .heartbeat-delay-1 {
          animation-delay: 0.5s;
        }

        .heartbeat-delay-2 {
          animation-delay: 1s;
        }

        .heartbeat-delay-3 {
          animation-delay: 1.5s;
        }

        .ai-thinking {
          animation: pulse-ring 3s ease-in-out infinite;
        }

        .ai-thinking-delay {
          animation-delay: 1s;
        }

        .animation-delay-100 {
          animation-delay: 100ms;
        }

        .animation-delay-200 {
          animation-delay: 200ms;
        }
      `}</style>
      <div className="min-h-screen bg-white">
      {/* Header */}
      <header className="border-b border-slate-200">
        <div className="max-w-4xl mx-auto px-4 py-6">
          <div className="flex items-center justify-center gap-3">
            <Headphones className="w-8 h-8 text-slate-600" />
            <h1 className="text-3xl font-light text-slate-900">å¨“å¨“</h1>
          </div>
          <p className="text-center text-slate-500 mt-2">AIè¯­éŸ³æ’­å®¢ç¼–å¯¼</p>
        </div>
      </header>

      {/* Main Content */}
      <div className="max-w-4xl mx-auto px-4 py-8">
        {/* Steps Progress */}
        <div className="flex justify-center mb-12">
          <div className="flex items-center gap-6">
            {steps.map((step, index) => (
              <div key={step.id} className="flex items-center gap-4">
                <div className="flex flex-col items-center">
                  <div
                    className={cn(
                      "w-16 h-16 rounded-full flex flex-col items-center justify-center text-sm transition-all duration-500 ease-out",
                      step.status === 'completed'
                        ? "bg-white border-2 border-slate-800 shadow-sm"
                        : step.status === 'recording'
                        ? "bg-white border-2 border-slate-800 shadow-md"
                        : "bg-white border-2 border-slate-200"
                    )}
                  >
                    {step.status === 'completed' ? (
                      <span className="text-slate-800 text-lg">âœ“</span>
                    ) : step.status === 'recording' ? (
                      <>
                        <span className="text-slate-800 font-light">{step.id}</span>
                        <div className="flex gap-1 mt-1">
                          <div className="w-1 h-1 bg-slate-800 rounded-full animate-pulse"></div>
                          <div className="w-1 h-1 bg-slate-800 rounded-full animate-pulse animation-delay-100"></div>
                          <div className="w-1 h-1 bg-slate-800 rounded-full animate-pulse animation-delay-200"></div>
                        </div>
                      </>
                    ) : (
                      <span className="text-slate-400 font-light">{step.id}</span>
                    )}
                  </div>
                  <span className={cn(
                    "text-xs mt-3 transition-all duration-500",
                    step.status === 'completed'
                      ? "text-slate-800 font-normal"
                      : step.status === 'recording'
                      ? "text-slate-800 font-medium"
                      : "text-slate-400 font-light"
                  )}>
                    {step.title}
                  </span>
                </div>
                {index < steps.length - 1 && (
                  <div className="relative">
                    <div
                      className={cn(
                        "w-12 h-px transition-all duration-500",
                        step.status === 'completed' ? "bg-slate-800" : "bg-slate-200"
                      )}
                    ></div>
                  </div>
                )}
              </div>
            ))}
          </div>
        </div>

        {/* Chat Area */}
        <div className="bg-slate-50 rounded-2xl p-6 mb-8 h-96 overflow-y-auto relative">
          {/* AIæ€è€ƒæ—¶çš„æ³¢çº¹æ•ˆæœ */}
          {isAiThinking && (
            <div className="absolute bottom-4 left-1/2 transform -translate-x-1/2 pointer-events-none">
              <div className="relative">
                <div className="absolute inset-0 w-16 h-16 rounded-full bg-gradient-to-r from-blue-400/20 to-indigo-400/20 ai-thinking"></div>
                <div className="absolute inset-0 w-16 h-16 rounded-full bg-gradient-to-r from-blue-400/15 to-indigo-400/15 ai-thinking ai-thinking-delay"></div>
                <div className="w-16 h-16 rounded-full bg-white/80 flex items-center justify-center backdrop-blur-sm">
                  <Sparkles className="w-6 h-6 text-blue-500 animate-pulse" />
                </div>
              </div>
            </div>
          )}

          <div className="space-y-4">
            {messages.map((message) => (
              <div
                key={message.id}
                className={cn(
                  "flex gap-3",
                  message.role === 'user' ? "justify-end" : "justify-start"
                )}
              >
                {message.role === 'assistant' && (
                  <div className="w-8 h-8 rounded-full bg-blue-500 flex items-center justify-center flex-shrink-0">
                    <Sparkles className="w-4 h-4 text-white" />
                  </div>
                )}
                <div
                  className={cn(
                    "max-w-md rounded-2xl px-4 py-3",
                    message.role === 'user'
                      ? "bg-slate-800 text-white"
                      : "bg-white border border-slate-200 text-slate-700"
                  )}
                >
                  {message.audioUrl && (
                    <audio controls className="w-full mb-2" src={message.audioUrl}>
                      æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘æ’­æ”¾
                    </audio>
                  )}
                  <p className="text-sm">{message.content}</p>
                </div>
                {message.role === 'user' && (
                  <div className="w-8 h-8 rounded-full bg-slate-700 flex items-center justify-center flex-shrink-0">
                    <Mic className="w-4 h-4 text-white" />
                  </div>
                )}
              </div>
            ))}
          </div>
        </div>

        {/* Podcast Player */}
        {podcastUrl && (
          <div className="bg-slate-50 rounded-2xl p-6 mb-8 border border-slate-200">
            <h3 className="text-xl font-bold mb-4 flex items-center gap-2 text-slate-800">
              <Sparkles className="w-6 h-6 text-slate-600" />
              ä½ çš„æ’­å®¢
            </h3>
            <audio controls className="w-full mb-4" src={podcastUrl}>
              æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘æ’­æ”¾
            </audio>
            {podcastScript && (
              <div className="bg-white rounded-lg p-4 mb-4 border border-slate-200">
                <h4 className="text-sm font-semibold text-slate-600 mb-2">æ’­å®¢æ–‡æ¡ˆ</h4>
                <pre className="text-sm text-slate-600 whitespace-pre-wrap">{podcastScript}</pre>
              </div>
            )}
            <div className="flex gap-3">
              <button className="flex items-center gap-2 px-4 py-2 bg-slate-700 hover:bg-slate-800 text-white rounded-lg transition-colors">
                <Share2 className="w-4 h-4" />
                åˆ†äº«
              </button>
              <button className="flex items-center gap-2 px-4 py-2 bg-slate-200 hover:bg-slate-300 text-slate-700 rounded-lg transition-colors">
                <Download className="w-4 h-4" />
                ä¸‹è½½
              </button>
            </div>
          </div>
        )}

        {/* Recording Area */}
        <div className="mt-8">
          {/* File Upload */}
          <div className="mb-6 text-center">
            <label className="inline-flex items-center gap-2 px-4 py-2 bg-slate-100 text-slate-700 rounded-lg hover:bg-slate-200 cursor-pointer transition-colors">
              <Upload className="w-4 h-4" />
              <span>ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ (MP3/WAV)</span>
              <input
                type="file"
                accept="audio/*"
                onChange={handleFileUpload}
                className="hidden"
              />
            </label>
          </div>

          {/* Recording Button */}
          <div className="flex justify-center">
            {!podcastUrl && (
              <div className="relative">
                {/* å½•éŸ³æ—¶çš„å¿ƒè·³æ³¢çº¹æ•ˆæœ */}
                {isRecording && (
                  <>
                    <div className="absolute inset-0 w-24 h-24 rounded-full bg-gradient-to-r from-rose-400/40 to-pink-400/40 heartbeat-animation"></div>
                    <div className="absolute inset-0 w-24 h-24 rounded-full bg-gradient-to-r from-rose-400/30 to-pink-400/30 heartbeat-animation heartbeat-delay-1"></div>
                    <div className="absolute inset-0 w-24 h-24 rounded-full bg-gradient-to-r from-rose-400/20 to-pink-400/20 heartbeat-animation heartbeat-delay-2"></div>
                    <div className="absolute inset-0 w-24 h-24 rounded-full bg-gradient-to-r from-rose-400/10 to-pink-400/10 heartbeat-animation heartbeat-delay-3"></div>
                  </>
                )}

                <button
                  onMouseDown={startRecording}
                  onMouseUp={stopRecording}
                  onTouchStart={startRecording}
                  onTouchEnd={stopRecording}
                  disabled={isProcessing}
                  className={cn(
                    "relative w-24 h-24 rounded-full flex flex-col items-center justify-center transition-all transform overflow-hidden",
                    isRecording
                      ? "bg-gradient-to-br from-rose-500 to-pink-600 scale-105 shadow-2xl shadow-rose-500/50"
                      : "bg-slate-600 hover:bg-slate-700 hover:scale-105 shadow-lg shadow-slate-600/30"
                  )}
                >
                  {isRecording && (
                    <div className="absolute inset-0 bg-white/20 animate-pulse"></div>
                  )}
                  {isRecording ? (
                    <>
                      <MicOff className="w-8 h-8 text-white mb-1 relative z-10 animate-pulse" />
                      <span className="text-xs text-white font-medium flex items-center gap-1 relative z-10">
                        <Clock className="w-3 h-3" />
                        {formatTime(recordingTime)}
                      </span>
                    </>
                  ) : (
                    <Mic className="w-8 h-8 text-white" />
                  )}
                </button>
              </div>
            )}
          </div>

          <p className="text-center mt-4 text-slate-500 text-sm">
            {isRecording ? 'æ¾å¼€ç»“æŸå½•éŸ³' : isProcessing ? 'æ­£åœ¨ç”Ÿæˆæ’­å®¢...' : 'æŒ‰ä½å½•éŸ³æˆ–ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶'}
          </p>

          {/* Upload Progress */}
          {isUploading && (
            <div className="mt-4 text-center">
              <div className="inline-flex items-center gap-2 text-sm text-blue-600">
                <div className="w-4 h-4 border-2 border-blue-600 border-t-transparent rounded-full animate-spin"></div>
                ä¸Šä¼ ä¸­...
              </div>
            </div>
          )}
        </div>

        {/* Processing Indicator */}
        {isProcessing && (
          <div className="fixed inset-0 bg-white bg-opacity-90 flex items-center justify-center">
            <div className="bg-white rounded-lg shadow-lg p-8 border border-slate-200">
              <div className="flex flex-col items-center">
                <div className="w-12 h-12 border-4 border-blue-600 border-t-transparent rounded-full animate-spin mb-4"></div>
                <p className="text-slate-700">æ­£åœ¨ç”Ÿæˆæ’­å®¢...</p>
              </div>
            </div>
          </div>
        )}
      </div>
    </div>
    </>
  )
}